{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D4v2vymw-ZX"
      },
      "source": [
        "**PRÁCTICA 2. RESOLUCIÓN DE PROBLEMAS DE OPTIMIZACIÓN MEDIANTE TENSORFLOW: ENTRENANDO UN PERCEPTRÓN SIMPLE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiFN7VY4z0Do"
      },
      "source": [
        "**Conceptos necesarios de teoría**:\n",
        "Tensores en TF, GradientTape, SGD, MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl42uGwRb_SZ"
      },
      "source": [
        "En la práctica anterior, programamos el **Fordward Pass** y el algoritmo básico del aprendizaje profundo, el **Backpropagation**, empleando la librería científica **Numpy**. El código que desarrollamos no estaba optimizado ni ampliamente validado. Debido a estos dos aspectos, cuando se desean entrenar redes neuronales se hace uso de librerias de más alto nivel. En esta segunda sesión práctica vamos a trabajar con la librería **TensorFlow**. ¿Como importamos dicha librería en nuestro Notebook de Colab?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh9LoykybaSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d9e9e7-2790-4a87-a452-93d8d738027b"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m694rgqLU77l"
      },
      "source": [
        "En **octubre de 2019**, TensorFlow llevó a cabo un gran cambio en el \n",
        "funcionamiento de su librería con la **release 2.x de TF**. El principal cambio fue la introducción del concepto de **EagerExecution** que permite ejecutar el grafo a la vez que se crea. En TF1.x primero se creaba el grafo y posteriormente se ejecutaba. TensorFlow es un framework desarrollado y mantenido por **Google** que permite la ejecución de operaciones matemáticas, mediante diagramas de flujo de datos, de una forma optimizada en una CPU o GPU. Vamos a **listar los dispositivos locales** para comprobar que tenemos disponible la GPU que Google Colab nos ofrece:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMkvxESycCYA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a625f4c-7dac-42fc-be0e-4dce20803570"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "def get_available_devices():\n",
        "  local_device_protos = device_lib.list_local_devices()\n",
        "  return [x.name for x in local_device_protos]\n",
        "\n",
        "print(get_available_devices())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/device:CPU:0', '/device:GPU:0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAdam6uPbapY"
      },
      "source": [
        "Tal y como hemos visto en el apartado teórico, TensorFlow tiene unas características un tanto peculiares:\n",
        "\n",
        "1.   TensorFlow utiliza **tensores** para almacenar los datos y realizar las operaciones.\n",
        "\n",
        "2.   En TensorFlow 2.x, se evalúan las operaciones realizadas directamente sin la necesidad de construir **grafos**.\n",
        "\n",
        "3.   Permite ejecutar el código implementado paralelamente o en **una o varias GPUs**, a elección del usuario.\n",
        "\n",
        "Sin más dilación vamos a ver como se define un tensor y como se pueden realizar operaciones básicas entre ellos. Ves ejecutando cada una de las celdas y asegúrate que comprendes la salida de todos los comandos *print*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynyaV6fJizJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0028b1c-3b3a-4cf2-9d0a-77171031c4fb"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Creo un numpy array\n",
        "arr1d = np.array([1, 5.5, 3, 15, 20])\n",
        "\n",
        "# Del cual puedo ver tanto su contenido como ciertas propiedades\n",
        "print(arr1d)\n",
        "print (arr1d.ndim)\n",
        "print (arr1d.shape)\n",
        "print (arr1d.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.   5.5  3.  15.  20. ]\n",
            "1\n",
            "(5,)\n",
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sEvamEOjA3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d1b71a7-5e0b-4e56-e3d3-518a48921390"
      },
      "source": [
        "# A continuación, podemos convertirlo en un tensor manteniendo las mismas propiedades que hemos visto anteriormente\n",
        "tensor1d = tf.convert_to_tensor(arr1d,tf.float64)\n",
        "print(tensor1d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 1.   5.5  3.  15.  20. ], shape=(5,), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WW7GKE6jQ8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69a64882-d786-42f6-e15b-1cf3f245ad13"
      },
      "source": [
        "# Vamos a sumar dos tensores\n",
        "tensor1d_bis = tf.convert_to_tensor([9, 4.5, 7, 5, 0], tf.float64)\n",
        "my_sum = tf.add(tensor1d, tensor1d_bis)\n",
        "print(my_sum)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10. 10. 10. 20. 20.], shape=(5,), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9izA32SGjVSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be39b182-32f4-415f-c3ee-c7bed133e6f7"
      },
      "source": [
        "# Multipliquemoslos (elemento a elemento)\n",
        "my_mul = tf.multiply(tensor1d, tensor1d_bis) # Producto elemento a elemento\n",
        "print(my_mul)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10. 10. 10. 20. 20.], shape=(5,), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4hsV_VfjgHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26236801-55c1-45a6-fd69-57fd5391bc2d"
      },
      "source": [
        "# Ahora un producto escalar de tensores 1D\n",
        "product1 = tf.tensordot(tensor1d, tensor1d_bis, 1) # OJO! No hace falta transponer\n",
        "print(product1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(129.75, shape=(), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4c_NMZ2pQTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3490f003-572b-43f1-e51a-d0ea3a78692d"
      },
      "source": [
        "# Vamos con un producto vectorial de tensores 2D\n",
        "matrix1 = tf.constant([[3., 3.]])\n",
        "matrix2 = tf.constant([[2.], [2.]])\n",
        "product2 = tf.matmul(matrix1, matrix2) # Producto matricial\n",
        "print(matrix1)\n",
        "print(matrix2)\n",
        "print(product2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[3. 3.]], shape=(1, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[2.]\n",
            " [2.]], shape=(2, 1), dtype=float32)\n",
            "tf.Tensor([[12.]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceSlmno7jxmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725c3a50-28a2-45cc-d26f-bd5a2f52c5ea"
      },
      "source": [
        "matrix1 = tf.constant([[1., 1.]])\n",
        "matrix2 = tf.constant([[2.], [2.]])\n",
        "product2 = tf.matmul(matrix1, matrix2) # Producto matricial\n",
        "print(product2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"MatMul:0\", shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh2i5weyaNIF"
      },
      "source": [
        "Como se ha comentado anteriormente, el código implementado se puede ejecutar en CPU, en GPU o en multiples GPUs. Mediante TF podemos listar los diferentes dispositivos (como ya hemos visto) y **ejecutar una sesión utilizando el/los dispositivo/s que creamos conveniente/s**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaTwBn40adFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77d84efa-fd5c-4052-ff7d-dda2825ead48"
      },
      "source": [
        "with tf.device(\"/device:XLA_GPU:0\"):\n",
        "  matrix1 = tf.constant([[3., 3.]])\n",
        "  matrix2 = tf.constant([[2.],[2.]])\n",
        "  last_prod = tf.matmul(matrix1, matrix2)\n",
        "  print(last_prod)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"MatMul:0\", shape=(1, 1), dtype=float32, device=/device:XLA_GPU:0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlgzGkeKRaC-"
      },
      "source": [
        "Una vez introducido lo que es un tensor y la forma de operar con ellos, vamos a dirigir ya el uso de TF al ámbito de las redes neuronales. Tal y como hemos visto en lo que llevamos de teoría como en la sesión práctica anterior, el **corazón de una red neuronal** es el algoritmo de **backpropagation** que tiene como objetivo optimizar los pesos **minimizando** la **función de pérdidas** o **función de coste**. ¿Y como podemos minimizar una determinada función empleando TF?  Pues vamos a verlo con un ejemplo, vamos a minimizar la función $f(x)=log(x)^2$: "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Hallemos el mínimo de la función y = log(x)^2\n",
        "x = tf.Variable(initial_value=2.0, dtype=tf.float32) # Le damos un primer valor a nuestra x\n",
        "optimizer = tf.optimizers.SGD(learning_rate=0.5) # Instanciamos el optimizador pasandole como parámetro el learning rate\n",
        "\n",
        "# Minimización\n",
        "for i in range(10):\n",
        "    with tf.GradientTape() as tape: # Crea un objeto GradientTape para registrar operaciones\n",
        "      tape.watch(x) #Vigilamos las variables a optimizar\n",
        "      y = tf.square(tf.math.log(x)) # Define la función a minimizar\n",
        "      grads = tape.gradient(y, x) # Calcula el gradiente de la función de pérdida con respecto a x\n",
        "      optimizer.apply_gradients(grads_and_vars=[(grads, x)]) # Actualiza el valor de x\n",
        "      print(\"Iteración: {}, x = {}, y = {}\".format(i, x.numpy(), y.numpy())) # Imprime el valor actual de x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJT1wKYhw9Ra",
        "outputId": "90056920-6c54-4ecd-dd40-389bee13bf60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración: 0, x = 1.6534264087677002, y = 0.4804530143737793\n",
            "Iteración: 1, x = 1.349300503730774, y = 0.25285786390304565\n",
            "Iteración: 2, x = 1.1272697448730469, y = 0.0897519513964653\n",
            "Iteración: 3, x = 1.0209965705871582, y = 0.014351693913340569\n",
            "Iteración: 4, x = 1.0006446838378906, y = 0.0004317743005231023\n",
            "Iteración: 5, x = 1.0000005960464478, y = 4.1534943306942296e-07\n",
            "Iteración: 6, x = 1.0, y = 3.552711781446699e-13\n",
            "Iteración: 7, x = 1.0, y = 0.0\n",
            "Iteración: 8, x = 1.0, y = 0.0\n",
            "Iteración: 9, x = 1.0, y = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzGZs1QKWpdL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "038f2562-0ee5-4519-98ff-cac551e3c8fc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Representa (empleando numpy y matplotlib la función f(x) = log(x)^2 (ver np.log) y obten el mínimo (np.min) y la posición del mismo (np.argmin)\n",
        "# Para ello, crea un vector de 100 puntos equiespaciados en el rango [0,10] (ver np.linspace)\n",
        "\n",
        "# Crear vector de puntos equiespaciados \n",
        "x_values = np.linspace(0, 10, 100) #(X)\n",
        "# Crear f(x)\n",
        "fx = np.log(x_values)**2 #(X)\n",
        "# Mostrar por pantalla el mínimo (junto con su posición) y graficar la función\n",
        "my_min = np.min(fx) #(X)\n",
        "idx_min = x_values[np.argmin(fx)] #(X) \n",
        "print('Mínimo de la función y = ', my_min, ' en x= ', idx_min) \n",
        "plt.plot(x_values,fx)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mínimo de la función y =  0.00010100925076817785  en x=  1.0101010101010102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f341f2ccc88>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgY3hhgjov4a"
      },
      "source": [
        "A continuación responda a las siguientes cuestiones acerca del ejemplo anterior:\n",
        "\n",
        "- ¿Tienden a la misma solución ambas aproximaciones?¿Que significa esto? **Sol.** Sí ambas aproximaciones tienden al mismo valor mínimo. El SGD nos da una solución bastante certera del mínimo global de la función\n",
        "- ¿Que efecto tendría sobre el valor del mínimo disminuir el valor de lr? **Sol.** Decrementar el lr puede significar que la precisión del mínimo aumente a costa de mayor CC\n",
        "- Disminuye la tasa de aprendizaje a lr = 0.05, ¿Que observas?¿Que parámetro del código necesitas modificar para observar resultados coherentes? **Sol.** No le da tiempo a aprender lo suficiente para proporcionar una buena solución. Hay que aumentar el número de steps (épocas) a entrenar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-37Suj7_-tb"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CCFoOHXwRcX"
      },
      "source": [
        "Para poner en práctica todo lo aprendido, vamos a resolver uno de aquellos problemas de optimización típicos de bachillerato mediante TensorFlow.\n",
        "\n",
        "**EJERCICIO 1.**  Xiaomi va a lanzar al mercado un nuevo smartphone y quiere diseñar el packaging del mismo. La idea es desarrollar un envase en forma de prisma de base cuadrada. El volumen del envase debe ser de 80 $cm^3$. El material para fabricar las caras laterales y la tapa del envase cuesta 1 céntimo de euro por $cm^2$. El material para fabricar la base debe ser más resistente y cuesta 1.5 céntimos de euro por $cm^2$.\n",
        "\n",
        "1.   Calcula las dimensiones del envase para que su coste sea el menor posible.\n",
        "2.   Calcula cuál es el coste mínimo, expresado en euros, que tendrá el envase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sshrnGCay12w"
      },
      "source": [
        "Si recordaís con los datos del encunciado debemos plantear un sistema de ecuaciones. Una de las ecuaciones nos proporcionará una relación y la otra será la función objetivo a minimizar. VAMOS ALLÁ:\n",
        "\n",
        "- El volumen de un prisma es $Vp = x * y * h$, como sabemos que la base es cuadrada: $Vp = x*x*h = 80$.\n",
        "- Por otra parte tenemos que plantear otra ecuación que involucre la superficie del envase y la relacione con el coste: $C(x) = 1c€/cm^2 * (4x*h + x^2) + 1.5 c€/cm^2 * x^2$ = $4xh+x^2 + 1.5x^2$ = $4xh+2.5x^2$.\n",
        "\n",
        "Bien, ahora que ya tenemos las dos ecuaciones, de la primera de ellas (la relación) despejamos $x$ y la sustituimos en la función de coste (función objetivo o función a minimizar), resultando:\n",
        "\n",
        "$C(x) = \\dfrac{320}{x} + 2.5x^2$\n",
        "\n",
        "Esta es la función objetivo que debeís minimizar haciendo uso de la librería TensorFlow, tal y como hemos hecho antes con la función $y = log(x)^2$, para poder responder a las dos cuestiones planteadas en el enunciado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMiT7B533qTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb9383f-49f0-485b-ac53-d97ed3eb09d8"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Hallemos el mínimo de la función C(x) = 320/x + 2.5x^2\n",
        "\n",
        "# Inicialización de la variable x (Busca documentación acerca de la función random_uniform de TF)\n",
        "x = tf.Variable(initial_value=tf.random.uniform([1], 0., 50.), name='x')\n",
        "\n",
        "# Instanciar el optimizador SGD pasándole como parámetro un valor de 0.005 de learning rate\n",
        "optimizer = tf.optimizers.SGD(learning_rate=0.005) #(X)\n",
        "\n",
        "old_solution = 0\n",
        "tolerance = 1e-4\n",
        "for step in range(500):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(x)\n",
        "        # Función de coste a minimizar (emplea tf.add, tf.divide, tf.multiply y tf.square)\n",
        "        c = tf.add(tf.divide(320,x), tf.multiply(2.5, tf.square(x)), name='c') #(X)\n",
        "        # Minimizamos la función objetivo\n",
        "        grads = tape.gradient(c, x) #(X)\n",
        "        # Actualizamos el valor de x\n",
        "        optimizer.apply_gradients(grads_and_vars=[(grads, x)]) #(X)\n",
        "        # Pedimos nueva solución de la variable x\n",
        "        solution = x.numpy()\n",
        "        # Comprobamos si se ha alcanzado la solución óptima\n",
        "        if np.abs(solution - old_solution) < tolerance:\n",
        "          print(\"\\n El envase óptimo tendrá dimensiones x = {} cm, h = {} cm dando lugar a un coste de C = {} €\".format(solution, 80/(solution*solution), c/100))\n",
        "          break\n",
        "        # Si no es así actualizo la solución vieja y muestro por pantalla 1 de cada 10 iteraciones\n",
        "        old_solution = solution\n",
        "        if step % 10 == 0:\n",
        "          print('[INFO]: Step ', step, \"---> x = \" + str(old_solution), \"- C = \" + str(c))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Step  0 ---> x = [28.852762] - C = tf.Tensor([2199.8381], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  10 ---> x = [22.42129] - C = tf.Tensor([1335.6227], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  20 ---> x = [17.442766] - C = tf.Tensor([817.56506], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  30 ---> x = [13.601442] - C = tf.Tensor([508.8839], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  40 ---> x = [10.657626] - C = tf.Tensor([327.27103], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  50 ---> x = [8.432727] - C = tf.Tensor([223.15181], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  60 ---> x = [6.796144] - C = tf.Tensor([166.41464], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  70 ---> x = [5.649359] - C = tf.Tensor([138.20338], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  80 ---> x = [4.9040527] - C = tf.Tensor([126.05766], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  90 ---> x = [4.4634805] - C = tf.Tensor([121.71457], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  100 ---> x = [4.226148] - C = tf.Tensor([120.427246], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  110 ---> x = [4.1070447] - C = tf.Tensor([120.09812], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  120 ---> x = [4.0498476] - C = tf.Tensor([120.021545], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  130 ---> x = [4.023025] - C = tf.Tensor([120.00462], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  140 ---> x = [4.010594] - C = tf.Tensor([120.00098], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  150 ---> x = [4.004866] - C = tf.Tensor([120.000206], shape=(1,), dtype=float32)\n",
            "[INFO]: Step  160 ---> x = [4.0022335] - C = tf.Tensor([120.000046], shape=(1,), dtype=float32)\n",
            "\n",
            " El envase óptimo tendrá dimensiones x = [4.0011973] cm, h = [4.997008] cm dando lugar a un coste de C = [1.2000002] €\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sodMxtm7rzG-"
      },
      "source": [
        "A continuación responda a las siguientes cuestiones acerca del ejemplo anterior:\n",
        "\n",
        "- ¿Qué valor de tasa de aprendizaje y número de pasos has utilizado para el entrenamiento? Si has empleado los valores del ejercicio anterior observarás un comportamiento un tanto extraño en el proceso de aprendizaje. ¿Que significa esto? **Sol.** La tasa de aprendizaje del ejercicio anterior es muy alta para alcanzar el mínimo global en este problema.\n",
        "\n",
        "- Prueba a fijar una tasa de aprendizaje 100 veces más pequeña para dar pasos mucho más cortos en la búsqueda de la solución óptima, por consiguiente establece un número de pasos mucho mayor, por ejemplo 500. ¿Que ocurre ahora? Justifica la respuesta. **Sol.** Ahora el proceso de aprendizaje es correcto y se obtienen resultados con mucho sentido. Con esto se ejemplifica perfectamente la importancia del learning rate y el número de épocas. Su influencia se estudiará detenidamente en la siguiente práctica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIsT3RXzfelM"
      },
      "source": [
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plPMuRcwbD_p"
      },
      "source": [
        "Después de familiarizarnos con la librería TensorFlow es el momento de implementar la segunda red neuronal del curso. El objetivo de dicha red va a ser el de **identificar digitos del 0 al 9 escritos de forma manual**. El set de datos **MNIST** es un conjunto de  70000 imágenes de $28 \\times 28$ pixels que contienen números manuscritos junto con la etiqueta solución del número codificado (i.e. nuestro ground truth). \n",
        "\n",
        "![mnist](https://drive.google.com/uc?id=1uvFNAFTVb58xPoSt_3F_9DLs47ZIyPFm)\n",
        "\n",
        "Cabe destacar que, por convención, MNIST dispone de una división específica en conjuntos de entrenamiento, validación y test. Este dataset es el \"Hola Mundo\" del aprendizaje profundo y es de gran utilidad para validar nuevos métodos propuestos ya que hace de *benchmark* permitiendo establecer comparativas justas. Debido a su gran popularidad las principales librerias destinadas al aprendizaje profundo permiten cargarlo directamente en nuestro código. Así que sin más dilación vamos a cargar los datos y a visualizarlos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm2jKyXgZ1Rs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "outputId": "7b53cea9-84db-4e49-93ab-fa34b4fa6fe2"
      },
      "source": [
        "# Imports necesarios\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importamos el dataset MNIST y cargamos los datos\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15)\n",
        "\n",
        "# Comprobar el tamaño del dataset\n",
        "print(\"El conjunto de entrenamiento tiene dimensiones: \", x_train.shape)\n",
        "print(\"El conjunto de validación tiene dimensiones: \",x_val.shape)\n",
        "print(\"El conjunto de test tiene dimensiones: \",x_test.shape)\n",
        "\n",
        "# Método para visualizar los datos de entrenamiento\n",
        "def display_digit(num):\n",
        "  # Seleccionar la imagen num de imagenes de train\n",
        "  image = x_train[num,:,:] #(X)\n",
        "  # Seleccionar el target num de y_train \n",
        "  label = y_train[num] #(X)\n",
        "  # Mostrar\n",
        "  plt.title('Example: %d  Label: %d' % (num, label))\n",
        "  plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
        "  plt.show()\n",
        "\n",
        "# Mostramos algunos ejemplos\n",
        "display_digit(np.random.randint(0, x_train.shape[0]))\n",
        "display_digit(np.random.randint(0, x_train.shape[0]))\n",
        "display_digit(np.random.randint(0, x_train.shape[0]))\n",
        "\n",
        "# Ejecuta el código varias veces y comprueba la variabilidad existente en los datos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de entrenamiento tiene dimensiones:  (51000, 28, 28)\n",
            "El conjunto de validación tiene dimensiones:  (9000, 28, 28)\n",
            "El conjunto de test tiene dimensiones:  (10000, 28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwKVmorKmdsP"
      },
      "source": [
        "**EJERCICIO 2.** Una vez visualizadas ciertas muestras de nuestro conjunto de datos,  vamos a entrenar un **perceptrón simple** (como el de la primera sesión). Recordad que en el perceptrón simple las entradas se ponderan por ciertos pesos y se suman en cada una de las neuronas de salida. Posteriormente emplearemos la función **Softmax** que hemos explicado en la sesión teórica, calculando las predicciones como $\\hat{Y}=softmax(X∗W+B)$ y minimizando la función de entropía cruzada o **cross-entropy** siguiendo la formula: \n",
        "\n",
        ">>>>>>>>$Coste = - \\displaystyle\\sum_j y_j log(p_j)$\n",
        "\n",
        "donde $y_j$ es el *ground truth* para la clase $j$ y $p_j$ el valor de probabilidad asignado a dicha clase a la salida."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiper-parámetros de nuestra red\n",
        "lr = 0.01\n",
        "n_epochs = 100\n",
        "batch_size = 128\n",
        "\n",
        "#Normalizamos los datos\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "x_val= x_val / 255.\n",
        "\n",
        "#Convertimos las imágenes a vectores, dado que aún no hemos visto cómo podemos implementar un modelo que trabaje con imágenes\n",
        "x_train = tf.reshape(x_train, shape=(51000, -1)) # Nuestros datos ya están en formato [N_instancias, variables] (60000 instancias, 784 (28+28) pixels).\n",
        "x_val = tf.reshape(x_val, shape=(9000, -1)) # Nuestros datos ya están en formato [N_instancias, variables] (9000 instancias, 784 (28+28) pixels).\n",
        "x_test = tf.reshape(x_test, shape=(10000, -1)) # Nuestros datos ya están en formato [N_instancias, variables] (10000 instancias, 784 (28+28) pixels).\n",
        "\n",
        "# Convertimos las etiquetas a one-hot y a float 64 ya que todos los datos deben estar en el mismo formato\n",
        "y_train = tf.one_hot(y_train, depth=10) #(X)\n",
        "y_val = tf.one_hot(y_val, depth=10) #(X)\n",
        "y_test = tf.one_hot(y_test, depth=10) #(X)\n",
        "\n",
        "y_train = tf.cast(y_train, 'float64') #(X)\n",
        "y_val= tf.cast(y_val, 'float64') #(X)\n",
        "y_test = tf.cast(y_test, 'float64') #(X)\n",
        "\n",
        "#Nos creamos ahora el iterador para que recorra nuestro dataset. Podéis leer más sobre tf.data aquí: https://www.tensorflow.org/guide/data\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_ds = train_ds.shuffle(10000).batch(batch_size)\n",
        "\n",
        "\n",
        "#Calculamos las iteraciones por época\n",
        "total_batch = x_train.shape[0] // batch_size\n",
        "\n",
        "#Creamos e inicializamos con ceros las variables W y b\n",
        "W = tf.zeros([784, 10], tf.double) #(X)\n",
        "b = tf.zeros([10], tf.double) #(X)\n",
        "\n",
        "# para almacenar el histórico de costes\n",
        "acc_epoch_tr = []\n",
        "acc_epoch_val = []\n",
        "loss_epoch_tr = []\n",
        "loss_epoch_val = []\n",
        "\n",
        "# 6. Entrenamiento de nuestra red\n",
        "for epoch in range(n_epochs):\n",
        "    avg_loss = 0.\n",
        "    avg_acc = 0.\n",
        "    \n",
        "    for batch_xs, batch_ys in train_ds:\n",
        "        # Empezamos con la optimización\n",
        "        # haremos uso de tf.GradientTape, que lleva un control de las variables\n",
        "        # para poder calcular sus gradientes\n",
        "        with tf.GradientTape() as tape:\n",
        "            # le indicamos que \"vigile\" las variables a optimizar\n",
        "            tape.watch(W) #(X)\n",
        "            tape.watch(b) #(X)\n",
        "            \n",
        "            # ejecutamos el modelo\n",
        "            pred = tf.nn.softmax(tf.matmul(batch_xs, W) + b) #(X)\n",
        "            # calculamos el accuracy (precisión)\n",
        "            correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(batch_ys, 1))\n",
        "            acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "            # Ahora, definimos nuestra función de pérdidas: esta vez, la cros-entropía\n",
        "            cost = tf.reduce_mean(-tf.reduce_sum(batch_ys*tf.math.log(pred), axis=1)) #(X)\n",
        "            # Calculamos los gradientes (gradient descent)\n",
        "            grad_W, grad_b = tape.gradient(cost, [W, b]) #(X)\n",
        "\n",
        "            # Definimos las operaciones para actualizar los pesos con los gradientes calculados\n",
        "            # y el learning rate\n",
        "            W = W - lr * grad_W #(X)\n",
        "            b = b - lr * grad_b #(X)\n",
        "\n",
        "        # Calculamos las perdidas y el accuracy teniendo en cuenta los batches que hay\n",
        "        avg_loss += cost / total_batch\n",
        "        avg_acc += acc / total_batch\n",
        "        \n",
        "    # Validamos el modelo en cada época\n",
        "    pred = tf.nn.softmax(tf.matmul(x_val, W) + b) #(X)\n",
        "    # Calculamos el accuracy (precisión)\n",
        "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y_val, 1))\n",
        "    acc_val = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    # Ahora, definimos nuestra función de pérdidas: esta vez, la cros-entropía\n",
        "    loss_val = tf.reduce_mean(-tf.reduce_sum(y_val*tf.math.log(pred), axis=1))  #(X)\n",
        "    # guardamos nuestro coste en el histórico\n",
        "    loss_epoch_tr.append(avg_loss) #(X)\n",
        "    acc_epoch_tr.append(avg_acc) #(X)\n",
        "    loss_epoch_val.append(loss_val) #(X)\n",
        "    acc_epoch_val.append(acc_val) #(X)\n",
        "\n",
        "    # imprimimos las iteraciones\n",
        "    print(\"[INFO]: Época {} ---> Acc_train = {} - Loss_train = {} - Acc_val = {} - Loss_val = {}\".format(epoch, avg_acc, avg_loss, acc_val, loss_val))\n",
        "\n",
        "\n",
        "print(\"Entrenamiento finalizado!!\")\n",
        "\n",
        "\n",
        "# Comprobamos lo que ha aprendido nuestra red testeando el modelo\n",
        "pred = tf.nn.softmax(tf.matmul(x_test, W) + b) #(X)\n",
        " \n",
        "# calculamos el accuracy (precisión)\n",
        "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y_test, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(\"Accuracy en test:\", accuracy.numpy())\n",
        "\n",
        "# Gráficar losses por época\n",
        "plt.plot(np.arange(0, n_epochs), loss_epoch_tr)\n",
        "plt.plot(np.arange(0, n_epochs), loss_epoch_val)\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Loss')\n",
        "  #¿Que se puede observar de las gráficas?¿Según hemos visto en la teoría, se aprecia overfitting?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lhiKMTSGWsrA",
        "outputId": "c0034651-0219-4010-89b9-def869cfbff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Época 0 ---> Acc_train = 0.7812139987945557 - Loss_train = 1.321060724964009 - Acc_val = 0.8304444551467896 - Loss_val = 0.8864030942749933\n",
            "[INFO]: Época 1 ---> Acc_train = 0.8478168845176697 - Loss_train = 0.753756932452287 - Acc_val = 0.8557778000831604 - Loss_val = 0.6677553911267565\n",
            "[INFO]: Época 2 ---> Acc_train = 0.8632341027259827 - Loss_train = 0.6145510505918075 - Acc_val = 0.8651111125946045 - Loss_val = 0.5780440256739517\n",
            "[INFO]: Época 3 ---> Acc_train = 0.8701664805412292 - Loss_train = 0.5476960881097321 - Acc_val = 0.8735555410385132 - Loss_val = 0.5274405392130587\n",
            "[INFO]: Época 4 ---> Acc_train = 0.8766160011291504 - Loss_train = 0.5067892374607672 - Acc_val = 0.8797777891159058 - Loss_val = 0.4944451157726773\n",
            "[INFO]: Época 5 ---> Acc_train = 0.8809179663658142 - Loss_train = 0.47871757458427655 - Acc_val = 0.8837777972221375 - Loss_val = 0.470773035350938\n",
            "[INFO]: Época 6 ---> Acc_train = 0.8839073181152344 - Loss_train = 0.45822803579021953 - Acc_val = 0.8875555396080017 - Loss_val = 0.45275769759516016\n",
            "[INFO]: Época 7 ---> Acc_train = 0.8866864442825317 - Loss_train = 0.44197746459601756 - Acc_val = 0.8893333077430725 - Loss_val = 0.4385758168586696\n",
            "[INFO]: Época 8 ---> Acc_train = 0.8891793489456177 - Loss_train = 0.4289368694935193 - Acc_val = 0.8920000195503235 - Loss_val = 0.4269778471423964\n",
            "[INFO]: Época 9 ---> Acc_train = 0.8910102844238281 - Loss_train = 0.4182399190978548 - Acc_val = 0.8943333625793457 - Loss_val = 0.4172707367563103\n",
            "[INFO]: Época 10 ---> Acc_train = 0.8927767276763916 - Loss_train = 0.40889210369868517 - Acc_val = 0.8949999809265137 - Loss_val = 0.40897479293881356\n",
            "[INFO]: Época 11 ---> Acc_train = 0.8942434191703796 - Loss_train = 0.40122897443290556 - Acc_val = 0.8968889117240906 - Loss_val = 0.40182597642054063\n",
            "[INFO]: Época 12 ---> Acc_train = 0.8961946368217468 - Loss_train = 0.39443314205109686 - Acc_val = 0.8975555300712585 - Loss_val = 0.39556339869673085\n",
            "[INFO]: Época 13 ---> Acc_train = 0.8970358967781067 - Loss_train = 0.38820358336980715 - Acc_val = 0.8989999890327454 - Loss_val = 0.3899792583381502\n",
            "[INFO]: Época 14 ---> Acc_train = 0.8981246948242188 - Loss_train = 0.3827097907388064 - Acc_val = 0.8996666669845581 - Loss_val = 0.3850720565056265\n",
            "[INFO]: Época 15 ---> Acc_train = 0.8989461660385132 - Loss_train = 0.37834608498198075 - Acc_val = 0.9004444479942322 - Loss_val = 0.3807363341973691\n",
            "[INFO]: Época 16 ---> Acc_train = 0.9004831910133362 - Loss_train = 0.37351596069746934 - Acc_val = 0.9013333320617676 - Loss_val = 0.37664011994939145\n",
            "[INFO]: Época 17 ---> Acc_train = 0.9012314081192017 - Loss_train = 0.3694804041296052 - Acc_val = 0.901888906955719 - Loss_val = 0.37296573844861336\n",
            "[INFO]: Época 18 ---> Acc_train = 0.9015681743621826 - Loss_train = 0.36572608000432794 - Acc_val = 0.9026666879653931 - Loss_val = 0.36958446979180715\n",
            "[INFO]: Época 19 ---> Acc_train = 0.9031244516372681 - Loss_train = 0.36211275193098424 - Acc_val = 0.9027777910232544 - Loss_val = 0.3665054155142368\n",
            "[INFO]: Época 20 ---> Acc_train = 0.9032562375068665 - Loss_train = 0.3590895218251534 - Acc_val = 0.9038888812065125 - Loss_val = 0.36363008155917415\n",
            "[INFO]: Época 21 ---> Acc_train = 0.904187023639679 - Loss_train = 0.3562896101787836 - Acc_val = 0.9042222499847412 - Loss_val = 0.36093129941208013\n",
            "[INFO]: Época 22 ---> Acc_train = 0.9044477343559265 - Loss_train = 0.35370148438542837 - Acc_val = 0.9053333401679993 - Loss_val = 0.3584847339983496\n",
            "[INFO]: Época 23 ---> Acc_train = 0.9050900340080261 - Loss_train = 0.35085977023163056 - Acc_val = 0.9051111340522766 - Loss_val = 0.35627790586002134\n",
            "[INFO]: Época 24 ---> Acc_train = 0.905819296836853 - Loss_train = 0.34869900794044917 - Acc_val = 0.9057777523994446 - Loss_val = 0.35409660498042406\n",
            "[INFO]: Época 25 ---> Acc_train = 0.9062033295631409 - Loss_train = 0.34633070850793723 - Acc_val = 0.9058889150619507 - Loss_val = 0.352024169687312\n",
            "[INFO]: Época 26 ---> Acc_train = 0.9066323637962341 - Loss_train = 0.34420639561837224 - Acc_val = 0.9064444303512573 - Loss_val = 0.3501132351260036\n",
            "[INFO]: Época 27 ---> Acc_train = 0.9074060916900635 - Loss_train = 0.34208428146245895 - Acc_val = 0.9065555334091187 - Loss_val = 0.348330813890478\n",
            "[INFO]: Época 28 ---> Acc_train = 0.9077374935150146 - Loss_train = 0.34045986129573225 - Acc_val = 0.9071111083030701 - Loss_val = 0.3465399202965081\n",
            "[INFO]: Época 29 ---> Acc_train = 0.9085643291473389 - Loss_train = 0.3384793736891 - Acc_val = 0.9071111083030701 - Loss_val = 0.3449934616947718\n",
            "[INFO]: Época 30 ---> Acc_train = 0.9085922241210938 - Loss_train = 0.33681425669320003 - Acc_val = 0.9079999923706055 - Loss_val = 0.3434729670615034\n",
            "[INFO]: Época 31 ---> Acc_train = 0.909372091293335 - Loss_train = 0.3351685494504388 - Acc_val = 0.9083333611488342 - Loss_val = 0.34195892796114186\n",
            "[INFO]: Época 32 ---> Acc_train = 0.9093720316886902 - Loss_train = 0.3337324141147539 - Acc_val = 0.9094444513320923 - Loss_val = 0.34069716431169395\n",
            "[INFO]: Época 33 ---> Acc_train = 0.909972071647644 - Loss_train = 0.3319965945998195 - Acc_val = 0.9091110825538635 - Loss_val = 0.33944628075168887\n",
            "[INFO]: Época 34 ---> Acc_train = 0.9103143811225891 - Loss_train = 0.33066537404229246 - Acc_val = 0.9098888635635376 - Loss_val = 0.3380608337704839\n",
            "[INFO]: Época 35 ---> Acc_train = 0.9108582735061646 - Loss_train = 0.3294670064981169 - Acc_val = 0.910111129283905 - Loss_val = 0.33684679937442913\n",
            "[INFO]: Época 36 ---> Acc_train = 0.9113178849220276 - Loss_train = 0.32776365902056914 - Acc_val = 0.9105555415153503 - Loss_val = 0.3356710495372387\n",
            "[INFO]: Época 37 ---> Acc_train = 0.9113548398017883 - Loss_train = 0.3267221589337194 - Acc_val = 0.9103333353996277 - Loss_val = 0.33458817802507396\n",
            "[INFO]: Época 38 ---> Acc_train = 0.9123026132583618 - Loss_train = 0.32556654013553915 - Acc_val = 0.910444438457489 - Loss_val = 0.3335605938955644\n",
            "[INFO]: Época 39 ---> Acc_train = 0.9122995734214783 - Loss_train = 0.3240709784360105 - Acc_val = 0.9108889102935791 - Loss_val = 0.33256912874817124\n",
            "[INFO]: Época 40 ---> Acc_train = 0.9127369523048401 - Loss_train = 0.32298674079581685 - Acc_val = 0.9106666445732117 - Loss_val = 0.3315655989797704\n",
            "[INFO]: Época 41 ---> Acc_train = 0.9128715991973877 - Loss_train = 0.322082421216723 - Acc_val = 0.9113333225250244 - Loss_val = 0.3306605274612475\n",
            "[INFO]: Época 42 ---> Acc_train = 0.9132252335548401 - Loss_train = 0.32120786664652107 - Acc_val = 0.9115555286407471 - Loss_val = 0.3297252820861571\n",
            "[INFO]: Época 43 ---> Acc_train = 0.9136428833007812 - Loss_train = 0.3200518637522407 - Acc_val = 0.9117777943611145 - Loss_val = 0.32890385880403733\n",
            "[INFO]: Época 44 ---> Acc_train = 0.9138927459716797 - Loss_train = 0.31896051568415484 - Acc_val = 0.9118888974189758 - Loss_val = 0.32802914299169217\n",
            "[INFO]: Época 45 ---> Acc_train = 0.9140077233314514 - Loss_train = 0.3179445164481157 - Acc_val = 0.9117777943611145 - Loss_val = 0.3272185325224688\n",
            "[INFO]: Época 46 ---> Acc_train = 0.9142373204231262 - Loss_train = 0.31696370168332094 - Acc_val = 0.9121111035346985 - Loss_val = 0.3264500702295055\n",
            "[INFO]: Época 47 ---> Acc_train = 0.9148262739181519 - Loss_train = 0.3161061940833083 - Acc_val = 0.9124444723129272 - Loss_val = 0.32569847384126\n",
            "[INFO]: Época 48 ---> Acc_train = 0.9147871732711792 - Loss_train = 0.3153709275806701 - Acc_val = 0.9125555753707886 - Loss_val = 0.32493465713177866\n",
            "[INFO]: Época 49 ---> Acc_train = 0.9149385094642639 - Loss_train = 0.3143814149005792 - Acc_val = 0.9126666784286499 - Loss_val = 0.32424309956375785\n",
            "[INFO]: Época 50 ---> Acc_train = 0.915255606174469 - Loss_train = 0.31349880511018685 - Acc_val = 0.9132221937179565 - Loss_val = 0.32360052152219715\n",
            "[INFO]: Época 51 ---> Acc_train = 0.9155187606811523 - Loss_train = 0.3130366614058749 - Acc_val = 0.9128888845443726 - Loss_val = 0.32302923786649357\n",
            "[INFO]: Época 52 ---> Acc_train = 0.9158723950386047 - Loss_train = 0.3119389670916893 - Acc_val = 0.9124444723129272 - Loss_val = 0.32238122836589317\n",
            "[INFO]: Época 53 ---> Acc_train = 0.915900468826294 - Loss_train = 0.31123800588895245 - Acc_val = 0.9136666655540466 - Loss_val = 0.3216973643778379\n",
            "[INFO]: Época 54 ---> Acc_train = 0.9158945679664612 - Loss_train = 0.31059702767459374 - Acc_val = 0.9136666655540466 - Loss_val = 0.32104458541264064\n",
            "[INFO]: Época 55 ---> Acc_train = 0.9160454273223877 - Loss_train = 0.3099250388334799 - Acc_val = 0.913777768611908 - Loss_val = 0.32040601514515\n",
            "[INFO]: Época 56 ---> Acc_train = 0.9162788987159729 - Loss_train = 0.3090815465460905 - Acc_val = 0.913777768611908 - Loss_val = 0.31998117009746657\n",
            "[INFO]: Época 57 ---> Acc_train = 0.9163155555725098 - Loss_train = 0.3086919827590763 - Acc_val = 0.914222240447998 - Loss_val = 0.3193363005081331\n",
            "[INFO]: Época 58 ---> Acc_train = 0.9168400168418884 - Loss_train = 0.30778539371284386 - Acc_val = 0.914222240447998 - Loss_val = 0.3187678994205175\n",
            "[INFO]: Época 59 ---> Acc_train = 0.917002260684967 - Loss_train = 0.30695506131921635 - Acc_val = 0.9131110906600952 - Loss_val = 0.3184051095794257\n",
            "[INFO]: Época 60 ---> Acc_train = 0.916965663433075 - Loss_train = 0.30655337594661997 - Acc_val = 0.9143333435058594 - Loss_val = 0.3177826726431375\n",
            "[INFO]: Época 61 ---> Acc_train = 0.9172043800354004 - Loss_train = 0.30574294596994084 - Acc_val = 0.913777768611908 - Loss_val = 0.3172818225513336\n",
            "[INFO]: Época 62 ---> Acc_train = 0.9171591401100159 - Loss_train = 0.30560175743729356 - Acc_val = 0.914222240447998 - Loss_val = 0.31680029403255106\n",
            "[INFO]: Época 63 ---> Acc_train = 0.9175603985786438 - Loss_train = 0.30477388313428966 - Acc_val = 0.9138888716697693 - Loss_val = 0.31636483906685875\n",
            "[INFO]: Época 64 ---> Acc_train = 0.9175938963890076 - Loss_train = 0.30418311893757816 - Acc_val = 0.9144444465637207 - Loss_val = 0.3158816133754095\n",
            "[INFO]: Época 65 ---> Acc_train = 0.9177589416503906 - Loss_train = 0.303855330997321 - Acc_val = 0.914555549621582 - Loss_val = 0.315382202980208\n",
            "[INFO]: Época 66 ---> Acc_train = 0.9182612895965576 - Loss_train = 0.3029899415398918 - Acc_val = 0.9139999747276306 - Loss_val = 0.3149819189913914\n",
            "[INFO]: Época 67 ---> Acc_train = 0.918466329574585 - Loss_train = 0.3025142296439494 - Acc_val = 0.9143333435058594 - Loss_val = 0.3146163230853023\n",
            "[INFO]: Época 68 ---> Acc_train = 0.9185028076171875 - Loss_train = 0.30207082433915833 - Acc_val = 0.914222240447998 - Loss_val = 0.3142093833223231\n",
            "[INFO]: Época 69 ---> Acc_train = 0.9185835719108582 - Loss_train = 0.30167371338890364 - Acc_val = 0.9152222275733948 - Loss_val = 0.3137375866789097\n",
            "[INFO]: Época 70 ---> Acc_train = 0.9192293286323547 - Loss_train = 0.3008662636163398 - Acc_val = 0.9152222275733948 - Loss_val = 0.31332801561511364\n",
            "[INFO]: Época 71 ---> Acc_train = 0.9189030528068542 - Loss_train = 0.30046278718749914 - Acc_val = 0.9146666526794434 - Loss_val = 0.3129219811781782\n",
            "[INFO]: Época 72 ---> Acc_train = 0.9191837310791016 - Loss_train = 0.3000717707750317 - Acc_val = 0.9144444465637207 - Loss_val = 0.312571358900199\n",
            "[INFO]: Época 73 ---> Acc_train = 0.9191925525665283 - Loss_train = 0.2997638152680021 - Acc_val = 0.9150000214576721 - Loss_val = 0.31220047748364727\n",
            "[INFO]: Época 74 ---> Acc_train = 0.9192823767662048 - Loss_train = 0.2991927176561092 - Acc_val = 0.9151111245155334 - Loss_val = 0.31182197724165467\n",
            "[INFO]: Época 75 ---> Acc_train = 0.9195850491523743 - Loss_train = 0.298809747272547 - Acc_val = 0.9152222275733948 - Loss_val = 0.31147027250939135\n",
            "[INFO]: Época 76 ---> Acc_train = 0.9196438193321228 - Loss_train = 0.2984110887614863 - Acc_val = 0.9151111245155334 - Loss_val = 0.3111427099624043\n",
            "[INFO]: Época 77 ---> Acc_train = 0.9196352958679199 - Loss_train = 0.29780853481890984 - Acc_val = 0.9151111245155334 - Loss_val = 0.3108148478002122\n",
            "[INFO]: Época 78 ---> Acc_train = 0.9199550747871399 - Loss_train = 0.29727288635697097 - Acc_val = 0.9151111245155334 - Loss_val = 0.31053021512882856\n",
            "[INFO]: Época 79 ---> Acc_train = 0.9199129939079285 - Loss_train = 0.2971164573330134 - Acc_val = 0.9152222275733948 - Loss_val = 0.31014214960739034\n",
            "[INFO]: Época 80 ---> Acc_train = 0.9200474619865417 - Loss_train = 0.29650875487852835 - Acc_val = 0.9153333306312561 - Loss_val = 0.3098672866576491\n",
            "[INFO]: Época 81 ---> Acc_train = 0.9199972748756409 - Loss_train = 0.2961221483582409 - Acc_val = 0.9154444336891174 - Loss_val = 0.30961980016825924\n",
            "[INFO]: Época 82 ---> Acc_train = 0.9203951954841614 - Loss_train = 0.29586182403593986 - Acc_val = 0.9155555367469788 - Loss_val = 0.30932148100828577\n",
            "[INFO]: Época 83 ---> Acc_train = 0.9201404452323914 - Loss_train = 0.29543532210745627 - Acc_val = 0.9152222275733948 - Loss_val = 0.30894338158571233\n",
            "[INFO]: Época 84 ---> Acc_train = 0.9206871390342712 - Loss_train = 0.2946922510029656 - Acc_val = 0.9155555367469788 - Loss_val = 0.30869997298853286\n",
            "[INFO]: Época 85 ---> Acc_train = 0.9206895232200623 - Loss_train = 0.29452866484631934 - Acc_val = 0.9157778024673462 - Loss_val = 0.3083699319322276\n",
            "[INFO]: Época 86 ---> Acc_train = 0.9205613136291504 - Loss_train = 0.2943277099264567 - Acc_val = 0.9157778024673462 - Loss_val = 0.3081252661835039\n",
            "[INFO]: Época 87 ---> Acc_train = 0.9207096099853516 - Loss_train = 0.29382445648260586 - Acc_val = 0.9161111116409302 - Loss_val = 0.3077828168023336\n",
            "[INFO]: Época 88 ---> Acc_train = 0.9208385348320007 - Loss_train = 0.2932556060476527 - Acc_val = 0.9161111116409302 - Loss_val = 0.30753328779811645\n",
            "[INFO]: Época 89 ---> Acc_train = 0.9208271503448486 - Loss_train = 0.2931070476224617 - Acc_val = 0.9166666865348816 - Loss_val = 0.30720933623706004\n",
            "[INFO]: Época 90 ---> Acc_train = 0.9209530353546143 - Loss_train = 0.29288160577161637 - Acc_val = 0.9163333177566528 - Loss_val = 0.306926555643397\n",
            "[INFO]: Época 91 ---> Acc_train = 0.9211664199829102 - Loss_train = 0.2925409549313571 - Acc_val = 0.9167777895927429 - Loss_val = 0.30673552243519714\n",
            "[INFO]: Época 92 ---> Acc_train = 0.9213488698005676 - Loss_train = 0.2920914487443282 - Acc_val = 0.9166666865348816 - Loss_val = 0.30646915094806093\n",
            "[INFO]: Época 93 ---> Acc_train = 0.9213376641273499 - Loss_train = 0.29181517875231777 - Acc_val = 0.9165555834770203 - Loss_val = 0.3062256249553978\n",
            "[INFO]: Época 94 ---> Acc_train = 0.9215702414512634 - Loss_train = 0.29113897952102896 - Acc_val = 0.9166666865348816 - Loss_val = 0.3059906088309965\n",
            "[INFO]: Época 95 ---> Acc_train = 0.9215453863143921 - Loss_train = 0.2908697586171887 - Acc_val = 0.9166666865348816 - Loss_val = 0.3058030157419226\n",
            "[INFO]: Época 96 ---> Acc_train = 0.9214801788330078 - Loss_train = 0.29066728867369546 - Acc_val = 0.9163333177566528 - Loss_val = 0.30553470925646387\n",
            "[INFO]: Época 97 ---> Acc_train = 0.9219966530799866 - Loss_train = 0.290263685945089 - Acc_val = 0.9172222018241882 - Loss_val = 0.3052624241407914\n",
            "[INFO]: Época 98 ---> Acc_train = 0.9215757846832275 - Loss_train = 0.2901756162050415 - Acc_val = 0.9169999957084656 - Loss_val = 0.30504901354038916\n",
            "[INFO]: Época 99 ---> Acc_train = 0.9214807748794556 - Loss_train = 0.28971409693561195 - Acc_val = 0.9169999957084656 - Loss_val = 0.30482535999865995\n",
            "Entrenamiento finalizado!!\n",
            "Accuracy en test: 0.9213\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}